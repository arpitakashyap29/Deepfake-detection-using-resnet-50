{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpitakashyap29/Deepfake-detection-using-resnet-50/blob/main/deepfake%20detection%20using%C2%A0resnet%C2%A050.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b90d8de-d697-45b9-8ffc-075f1cc50e9c",
      "metadata": {
        "id": "5b90d8de-d697-45b9-8ffc-075f1cc50e9c"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9122335c-6f0d-4ad2-9a09-f2155e1ad5df",
      "metadata": {
        "id": "9122335c-6f0d-4ad2-9a09-f2155e1ad5df"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2300847-017c-4c10-bf29-1e905b99c378",
      "metadata": {
        "id": "e2300847-017c-4c10-bf29-1e905b99c378"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ead05dd-cce5-4b63-8f75-907cdf54ed06",
      "metadata": {
        "id": "4ead05dd-cce5-4b63-8f75-907cdf54ed06"
      },
      "outputs": [],
      "source": [
        "!python -m pip install -qq kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45acdb20-a973-4ce8-b868-48b048dc76e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45acdb20-a973-4ce8-b868-48b048dc76e8",
        "outputId": "d5a87f68-e3cd-4b62-bc4b-8772141e2938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/asifmzx/celeb-v1-df\n",
            "License(s): MIT\n",
            "Downloading celeb-v1-df.zip to /content\n",
            " 99% 1.97G/1.98G [00:30<00:00, 103MB/s]\n",
            "100% 1.98G/1.98G [00:30<00:00, 70.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d asifmzx/celeb-v1-df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aea21ab1-ddac-4dd7-9c32-eabb7030e908",
      "metadata": {
        "id": "aea21ab1-ddac-4dd7-9c32-eabb7030e908"
      },
      "outputs": [],
      "source": [
        "!unzip -q celeb-v1-df.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8de81195-c834-488c-9311-3f9da9f7ce94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8de81195-c834-488c-9311-3f9da9f7ce94",
        "outputId": "73092dae-abb4-4df0-c4ab-26f4bb3038be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy pandas opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb0525a9-7650-4141-a501-2a8aaf800c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb0525a9-7650-4141-a501-2a8aaf800c97",
        "outputId": "e525a037-4fac-4ff7-ac6b-12d87a83e6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow numpy pandas opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d0d8d7-0bfc-48f7-aa83-2b89e4039463",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68d0d8d7-0bfc-48f7-aa83-2b89e4039463",
        "outputId": "ad5ede3a-802a-4261-e7cf-e9f7995026c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 170MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31ea29e-77ba-49c8-8998-b8e969cb1e83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b31ea29e-77ba-49c8-8998-b8e969cb1e83",
        "outputId": "878d2ae7-27df-452b-ecb5-a871f57ab656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision opencv-python pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d67351-ecff-459e-a96e-128652f7a805",
      "metadata": {
        "id": "47d67351-ecff-459e-a96e-128652f7a805"
      },
      "outputs": [],
      "source": [
        "test_videos = []\n",
        "with open('List_of_testing_videos.txt', 'r') as file:\n",
        "    test_videos = file.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be828b2-6903-4e8c-804d-bbcb567a4ce8",
      "metadata": {
        "id": "7be828b2-6903-4e8c-804d-bbcb567a4ce8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "real_videos_path = 'Celeb-real'\n",
        "fake_videos_path = 'Celeb-synthesis'\n",
        "# Temporary directories for extracted frames\n",
        "temp_real_frames = 'temp_frames/real'\n",
        "temp_fake_frames = 'temp_frames/fake'\n",
        "# Paths for training and testing frames\n",
        "train_real_images_path = 'train/real/'\n",
        "train_fake_images_path = 'train/fake/'\n",
        "test_real_images_path = 'test/real/'\n",
        "test_fake_images_path = 'test/fake/'\n",
        "\n",
        "\n",
        "os.makedirs(temp_real_frames, exist_ok=True)\n",
        "os.makedirs(temp_fake_frames, exist_ok=True)\n",
        "os.makedirs(train_real_images_path, exist_ok=True)\n",
        "os.makedirs(train_fake_images_path, exist_ok=True)\n",
        "os.makedirs(test_real_images_path, exist_ok=True)\n",
        "os.makedirs(test_fake_images_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecf9282-36bd-49ba-9158-dde9c1f332e7",
      "metadata": {
        "id": "4ecf9282-36bd-49ba-9158-dde9c1f332e7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "def extract_frames(video_path, output_folder, frame_rate=5, similarity_threshold=1000):\n",
        "    \"\"\"\n",
        "    Extract frames from a video file, removing duplicates, and save them to the output folder.\n",
        "\n",
        "    Args:\n",
        "    - video_path: str, path to the video file.\n",
        "    - output_folder: str, path to save the extracted frames.\n",
        "    - frame_rate: int, number of frames to skip before extracting a new one.\n",
        "    - similarity_threshold: float, MSE threshold to consider frames as different.\n",
        "    \"\"\"\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    count = 0\n",
        "    success, prev_frame = video.read()  # Read the first frame\n",
        "\n",
        "    if not success:\n",
        "        print(f\"Failed to read the video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Save the first frame\n",
        "    frame_filename = os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(video_path))[0]}frame{count}.jpg\")\n",
        "    cv2.imwrite(frame_filename, prev_frame)\n",
        "\n",
        "    while True:\n",
        "        # Read the next frame\n",
        "        success, frame = video.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Skip frames to achieve the desired frame rate\n",
        "        count += 1\n",
        "        if count % frame_rate != 0:\n",
        "            continue\n",
        "\n",
        "        # Compute the similarity between the current frame and the previous saved frame\n",
        "        if mse(prev_frame, frame) > similarity_threshold:\n",
        "            # If different enough, save the frame\n",
        "            frame_filename = os.path.join(output_folder, f\"{os.path.splitext(os.path.basename(video_path))[0]}frame{count}.jpg\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "            prev_frame = frame  # Update the previous frame\n",
        "\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def mse(imageA, imageB):\n",
        "    \"\"\"\n",
        "    Compute the Mean Squared Error between two images.\n",
        "    The lower the MSE, the more similar the images are.\n",
        "    \"\"\"\n",
        "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
        "    return err"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b23861-d8c0-469c-bf5d-5192ba4633a2",
      "metadata": {
        "id": "a7b23861-d8c0-469c-bf5d-5192ba4633a2"
      },
      "outputs": [],
      "source": [
        "for video_file in os.listdir(real_videos_path):\n",
        "    extract_frames(os.path.join(real_videos_path, video_file), temp_real_frames)\n",
        "\n",
        "for video_file in os.listdir(fake_videos_path):\n",
        "    extract_frames(os.path.join(fake_videos_path, video_file), temp_fake_frames)\n",
        "\n",
        "real_frames = [os.path.join(temp_real_frames, f) for f in os.listdir(temp_real_frames)]\n",
        "fake_frames = [os.path.join(temp_fake_frames, f) for f in os.listdir(temp_fake_frames)]\n",
        "\n",
        "# Split frames into training and testing sets (80-20 split)\n",
        "train_real, test_real = train_test_split(real_frames, test_size=0.2, random_state=42)\n",
        "train_fake, test_fake = train_test_split(fake_frames, test_size=0.2, random_state=42)\n",
        "\n",
        "# Move frames to the corresponding train/test directories\n",
        "for frame in train_real:\n",
        "    shutil.move(frame, train_real_images_path)\n",
        "for frame in test_real:\n",
        "    shutil.move(frame, test_real_images_path)\n",
        "for frame in train_fake:\n",
        "    shutil.move(frame, train_fake_images_path)\n",
        "for frame in test_fake:\n",
        "    shutil.move(frame, test_fake_images_path)\n",
        "\n",
        "# Clean up temporary directories\n",
        "shutil.rmtree(temp_real_frames)\n",
        "shutil.rmtree(temp_fake_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e466d4-5972-467b-a8e4-eccabb44c0d6",
      "metadata": {
        "id": "c3e466d4-5972-467b-a8e4-eccabb44c0d6"
      },
      "outputs": [],
      "source": [
        "def is_test_video(video_file, test_videos_list):\n",
        "    return video_file in test_videos_list\n",
        "\n",
        "# Separate videos into training and testing sets\n",
        "for video_file in os.listdir(real_videos_path):\n",
        "    video_name = video_file.split('.')[0]\n",
        "    if is_test_video(video_name, test_videos):\n",
        "        extract_frames(os.path.join(real_videos_path, video_file), test_real_images_path)\n",
        "    else:\n",
        "        extract_frames(os.path.join(real_videos_path, video_file), train_real_images_path)\n",
        "\n",
        "for video_file in os.listdir(fake_videos_path):\n",
        "    video_name = video_file.split('.')[0]\n",
        "    if is_test_video(video_name, test_videos):\n",
        "        extract_frames(os.path.join(fake_videos_path, video_file), test_fake_images_path)\n",
        "    else:\n",
        "        extract_frames(os.path.join(fake_videos_path, video_file), train_fake_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "987e6a5b-362f-4b8d-9b40-6c8fb95464d4",
      "metadata": {
        "id": "987e6a5b-362f-4b8d-9b40-6c8fb95464d4"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize frames to 224x224 pixels\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip frames horizontally\n",
        "    transforms.ToTensor(),  # Convert frames to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354062c8-dfb5-4127-b0c5-213eda54d281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354062c8-dfb5-4127-b0c5-213eda54d281",
        "outputId": "b5ddd028-6358-44cd-a780-9e4e12a3af18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 117MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Load pre-trained ResNet\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer for binary classification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # Binary output: Real vs. Fake\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430e4868-155d-482c-9b1e-34250c447e5a",
      "metadata": {
        "id": "430e4868-155d-482c-9b1e-34250c447e5a"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Learning rate scheduler to adjust learning rate over time\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1399e786-2bb9-4060-9f8f-c26266f909b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1399e786-2bb9-4060-9f8f-c26266f909b6",
        "outputId": "ed26715d-d81d-4ee3-f685-6a5bd805e36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.2429\n",
            "Epoch 2/5, Loss: 0.1020\n",
            "Epoch 3/5, Loss: 0.0701\n",
            "Epoch 4/5, Loss: 0.0458\n",
            "Epoch 5/5, Loss: 0.0416\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "\n",
        "# Load the training data\n",
        "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Number of epochs to train\n",
        "num_epochs = 5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Step the learning rate scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686aa720-bb9a-4ae6-90db-32b174500c83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "686aa720-bb9a-4ae6-90db-32b174500c83",
        "outputId": "875bb736-79c8-45b7-e1d9-3fec1d70b0f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 98.94%\n"
          ]
        }
      ],
      "source": [
        "test_dataset = datasets.ImageFolder('/content/test', transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# Initialize lists to store predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())  # Move to CPU and convert to numpy\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "AFbJnREIH2k6",
        "outputId": "07bb32a2-f60d-4e19-bbb2-4b6c72c7935a"
      },
      "id": "AFbJnREIH2k6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2897   26]\n",
            " [  20  556]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      2923\n",
            "           1       0.96      0.97      0.96       576\n",
            "\n",
            "    accuracy                           0.99      3499\n",
            "   macro avg       0.97      0.98      0.98      3499\n",
            "weighted avg       0.99      0.99      0.99      3499\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}